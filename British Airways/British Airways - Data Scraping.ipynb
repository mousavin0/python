{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fa71db",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fd22ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "import re\n",
    "\n",
    "#Read the review page on British Airways from airlinequality.com\n",
    "URL = 'https://www.airlinequality.com/airline-reviews/british-airways'\n",
    "number_of_comments_per_pages=100\n",
    "link_arguments='/?sortby=post_date%3ADesc&pagesize='\n",
    "first_page_URL=URL+link_arguments+str(number_of_comments_per_pages)\n",
    "req = requests.get(first_page_URL)\n",
    "url_parsed = bs(req.text, 'html.parser')\n",
    "\n",
    "\n",
    "#Find the number of pages\n",
    "navigation = url_parsed.find(\"div\", class_='pagination-total')\n",
    "pattern = re.compile(\"\\d+ to \\d+ of (\\d+) Reviews\")\n",
    "number_of_pages=int(int(pattern.search(navigation.text.strip()).group(1))/number_of_comments_per_pages)\n",
    "print(number_of_pages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74e08a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 9, 1, 3, 4, 5, 1, 1, 2, 8, 6, 4, 4, 3, 1, 1, 8, 3, 1, 1, 2, 2, 5, 6, 1, 8, 3, 6, 3, 4, 3, 1, 9, 2, 7, 7, 1, 4, 1, 2, 1, 5, 1, 1, 1, 6, 1, 9, 9, 3, 9, 2, 8, 1, 3, 7, 8, 9, 1, 10, 3, 6, 7, 8, 3, 9, 1, 10, 10, 4, 5, 1, 2, 2, 7, 1, 4, 1, 10, 9, 1, 1, 1, 10, 10, 1, 8, 1, 1, 2, 2, 8, 1, 1, 1, 5, 5, 7, 1, 10]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reviews= []\n",
    "ratings=[]\n",
    "headers=[]\n",
    "#Save first page's reviews'headers and contents and rankings\n",
    "for review in url_parsed.find_all('div',attrs={'itemprop':'reviewBody'}):\n",
    "    reviews.append(review.text.strip().partition('|')[2]+\" \")\n",
    "for header in url_parsed.find_all('h2',class_='text_header'):\n",
    "    headers.append(header.text.strip()[1:-1]+\" \")\n",
    "#The first rating in all pages is the overall rate\n",
    "rating_tags=url_parsed.find_all('span',attrs={'itemprop':'ratingValue'})\n",
    "for rating in rating_tags[1:]:\n",
    "    ratings.append(int(rating.text.strip())+ 0)\n",
    "\n",
    "overall_rating = int(rating_tags[0].text.strip())\n",
    "#print(reviews)\n",
    "#print(headers)\n",
    "print(ratings)\n",
    "print(overall_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b02cc3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "for i in range(2,int(number_of_pages)):\n",
    "    sleep(randint(3, 7))\n",
    "    next_page=URL+'/page/'+str(i)+link_arguments+str(number_of_comments_per_pages)\n",
    "    next_page_req = requests.get(next_page)\n",
    "    next_page_parsed = bs(next_page_req.text, 'html.parser')\n",
    "    for review in next_page_parsed.find_all('div',attrs={'itemprop':'reviewBody'}):\n",
    "        reviews.append(review.text.strip().partition('|')[2]+\" \")\n",
    "    for header in url_parsed.find_all('h2',class_='text_header'):\n",
    "        headers.append(header.text.strip()[1:-1]+\" \")\n",
    "    rating_tags=url_parsed.find_all('span',attrs={'itemprop':'ratingValue'})\n",
    "    for rating in rating_tags[1:]:\n",
    "        ratings.append(int(rating.text.strip())+0)\n",
    "        \n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cda2eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)\n",
    "len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a41d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_dict = {'Header':headers, 'Review':reviews, 'Rating':ratings} \n",
    "df = pd.DataFrame(list_dict) \n",
    "df.to_csv('British_Airways_Reviews.csv', index=False) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
